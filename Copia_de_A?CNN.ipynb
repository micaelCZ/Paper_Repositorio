{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmW8kHlrvdiPq3KP2KF+ey",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/micaelCZ/Paper_Repositorio/blob/main/Copia_de_A%3FCNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5YobagDnJDV",
        "outputId": "24bdfcaa-eb6e-4a3a-c675-3d12be4c6a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade scikit-learn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, MaxPooling1D, BatchNormalization, Dropout, Dense, Flatten\n",
        "import urllib\n",
        "\n",
        "# Descargar el archivo CSV\n",
        "url = 'https://github.com/jonathan-elian-toapanta/INTERNETWORKING/raw/main/ESCENARIOS/ScenarioA.csv'\n",
        "filename = 'ScenarioA.csv'\n",
        "urllib.request.urlretrieve(url, filename)\n",
        "\n",
        "# Leer el archivo CSV\n",
        "dataframe = pd.read_csv(filename, low_memory=False, sep=',')\n",
        "\n",
        "     \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize\n",
        "def dfNormalize(df):\n",
        "    for feature_name in df.columns:\n",
        "        df.loc[:,feature_name]= pd.to_numeric(df.loc[:,feature_name], errors='coerce').fillna(0)\n",
        "        max_value = df[feature_name].max()\n",
        "        min_value = df[feature_name].min()   \n",
        "        if (max_value - min_value) > 0:\n",
        "            df.loc[:,feature_name] = (df.loc[:,feature_name] - min_value) / (max_value - min_value)\n",
        "        else:\n",
        "            df.loc[:,feature_name] = (df.loc[:,feature_name]- min_value)    \n",
        "    return df\n",
        "     \n",
        "\n",
        "dataframe = dataframe.reindex(np.random.permutation(dataframe.index)).copy()\n",
        "\n",
        "     \n",
        "\n",
        "keys = dataframe.keys()\n",
        "data_to_process = dataframe[keys[4:len(keys) - 1]].copy()\n",
        "x_normalised = dfNormalize(data_to_process)\n",
        "print(x_normalised.describe())\n",
        "change_labels = lambda x: 1 if x == 'nonTOR' else 0\n",
        "     \n",
        "\n",
        "y_normalised = dataframe['label'].apply(change_labels)\n",
        "\n",
        "     \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_normalised,\n",
        "                                            y_normalised, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQ-q8L_GYm6l",
        "outputId": "5462a7ae-d068-4eab-8050-bf26cf252a35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-27ed442ad592>:8: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  df.loc[:,feature_name] = (df.loc[:,feature_name] - min_value) / (max_value - min_value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Protocol   Flow Duration   Flow Bytes/s   Flow Packets/s  \\\n",
            "count  67834.000000    67834.000000        67830.0          67828.0   \n",
            "mean       0.560663        0.299188            0.0              0.0   \n",
            "std        0.496310        0.406300            0.0              0.0   \n",
            "min        0.000000        0.000000            0.0              0.0   \n",
            "25%        0.000000        0.004436            0.0              0.0   \n",
            "50%        1.000000        0.041086            0.0              0.0   \n",
            "75%        1.000000        0.732555            0.0              0.0   \n",
            "max        1.000000        1.000000            0.0              0.0   \n",
            "\n",
            "        Flow IAT Mean   Flow IAT Std   Flow IAT Max   Flow IAT Min  \\\n",
            "count    67834.000000   67834.000000   67834.000000   67834.000000   \n",
            "mean         0.031600       0.031363       0.089855       0.019491   \n",
            "std          0.069971       0.090973       0.173880       0.057865   \n",
            "min          0.000000       0.000000       0.000000       0.000000   \n",
            "25%          0.000996       0.000000       0.002893       0.000228   \n",
            "50%          0.008355       0.000000       0.017866       0.000363   \n",
            "75%          0.041114       0.008219       0.046420       0.021001   \n",
            "max          1.000000       1.000000       1.000000       1.000000   \n",
            "\n",
            "       Fwd IAT Mean   Fwd IAT Std  ...   Bwd IAT Max   Bwd IAT Min  \\\n",
            "count  67834.000000  67834.000000  ...  67834.000000  67834.000000   \n",
            "mean       0.035016      0.032576  ...      0.047617      0.005193   \n",
            "std        0.083937      0.096226  ...      0.141009      0.048749   \n",
            "min        0.000000      0.000000  ...      0.000000      0.000000   \n",
            "25%        0.000000      0.000000  ...      0.000000      0.000033   \n",
            "50%        0.001997      0.000000  ...      0.000000      0.000033   \n",
            "75%        0.041135      0.004295  ...      0.008281      0.000034   \n",
            "max        1.000000      1.000000  ...      1.000000      1.000000   \n",
            "\n",
            "        Active Mean   Active Std    Active Max    Active Min     Idle Mean  \\\n",
            "count  67834.000000      67834.0  67834.000000  67834.000000  67834.000000   \n",
            "mean       0.007775          0.0      0.007775      0.007775      0.030856   \n",
            "std        0.063094          0.0      0.063094      0.063094      0.145423   \n",
            "min        0.000000          0.0      0.000000      0.000000      0.000000   \n",
            "25%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
            "50%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
            "75%        0.000000          0.0      0.000000      0.000000      0.000000   \n",
            "max        1.000000          0.0      1.000000      1.000000      1.000000   \n",
            "\n",
            "        Idle Std      Idle Max      Idle Min  \n",
            "count    67834.0  67834.000000  67834.000000  \n",
            "mean         0.0      0.030856      0.030856  \n",
            "std          0.0      0.145423      0.145423  \n",
            "min          0.0      0.000000      0.000000  \n",
            "25%          0.0      0.000000      0.000000  \n",
            "50%          0.0      0.000000      0.000000  \n",
            "75%          0.0      0.000000      0.000000  \n",
            "max          0.0      1.000000      1.000000  \n",
            "\n",
            "[8 rows x 24 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Verificar si hay valores nulos en x_train e y_train\n",
        "print(np.isnan(X_train).any())\n",
        "print(np.isnan(y_train).any())\n",
        "\n",
        "# Reemplazar valores nulos por cero\n",
        "x_train = np.nan_to_num(X_train, nan=0.0)\n",
        "y_train = np.nan_to_num(y_train, nan=0.0)\n",
        "\n",
        "# Definir el modelo de la CNN\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(x_train.shape[1], 1)))\n",
        "    model.add(Conv1D(filters=32, kernel_size=3, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling1D(pool_size=2))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compilar el modelo\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "# Crear el modelo\n",
        "model = create_model()\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Hacer predicciones sobre los datos de prueba\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Convertir las probabilidades en etiquetas binarias (0 o 1) usando un umbral de 0.5\n",
        "y_pred_binary = (y_pred > 0.5).astype(int)\n",
        " \n",
        "# calcular métricas de evaluación\n",
        "acc = accuracy_score(y_test, y_pred_binary)*100\n",
        "f1 = f1_score(y_test, y_pred_binary, average='weighted')*100\n",
        "prec = precision_score(y_test, y_pred_binary, average='weighted')*100\n",
        "rec = recall_score(y_test, y_pred_binary, average='weighted')*100\n",
        "\n",
        "print('Accuracy: %.2f' % acc)\n",
        "print('F1 score: %.2f' % f1)\n",
        "print('Precision: %.2f' % prec)\n",
        "print('Recall: %.2f' % rec)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Reemplazar valores nulos por cero\n",
        "x_test = np.nan_to_num(X_test, nan=0.0)\n",
        "y_test = np.nan_to_num(y_test, nan=0.0)\n",
        "\n",
        "# Predice las probabilidades de las clases para los datos de prueba\n",
        "y_pred_prob = model.predict(x_test)\n",
        "\n",
        "# Calcula la curva ROC y el área bajo la curva (AUC)\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VvR76GMaXe5F",
        "outputId": "b96f80d6-bf05-4081-e2bf-202d829d5b1e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Protocol          False\n",
            " Flow Duration     False\n",
            " Flow Bytes/s       True\n",
            " Flow Packets/s     True\n",
            " Flow IAT Mean     False\n",
            " Flow IAT Std      False\n",
            " Flow IAT Max      False\n",
            " Flow IAT Min      False\n",
            "Fwd IAT Mean       False\n",
            " Fwd IAT Std       False\n",
            " Fwd IAT Max       False\n",
            " Fwd IAT Min       False\n",
            "Bwd IAT Mean       False\n",
            " Bwd IAT Std       False\n",
            " Bwd IAT Max       False\n",
            " Bwd IAT Min       False\n",
            "Active Mean        False\n",
            " Active Std        False\n",
            " Active Max        False\n",
            " Active Min        False\n",
            "Idle Mean          False\n",
            " Idle Std          False\n",
            " Idle Max          False\n",
            " Idle Min          False\n",
            "dtype: bool\n",
            "False\n",
            "Epoch 1/10\n",
            "1484/1484 [==============================] - 36s 21ms/step - loss: nan - accuracy: 0.4284 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 2/10\n",
            "1484/1484 [==============================] - 16s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 3/10\n",
            "1484/1484 [==============================] - 17s 12ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 4/10\n",
            "1484/1484 [==============================] - 16s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 5/10\n",
            "1484/1484 [==============================] - 17s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 6/10\n",
            "1484/1484 [==============================] - 17s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 7/10\n",
            "1484/1484 [==============================] - 16s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 8/10\n",
            "1484/1484 [==============================] - 16s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 9/10\n",
            "1484/1484 [==============================] - 16s 11ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "Epoch 10/10\n",
            "1484/1484 [==============================] - 18s 12ms/step - loss: nan - accuracy: 0.1176 - val_loss: nan - val_accuracy: 0.1208\n",
            "636/636 [==============================] - 2s 3ms/step\n",
            "Accuracy: 12.08\n",
            "F1 score: 2.61\n",
            "Precision: 1.46\n",
            "Recall: 12.08\n",
            "  1/636 [..............................] - ETA: 1:28"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "636/636 [==============================] - 2s 3ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e77ca3e4d5eb>\u001b[0m in \u001b[0;36m<cell line: 72>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Calcula la curva ROC y el área bajo la curva (AUC)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    753\u001b[0m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;31m# Filter out zero-weighted samples, as they should not impact the result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[0;34m(X, allow_nan, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mdocumentation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \"\"\"\n\u001b[0;32m--> 190\u001b[0;31m     _assert_all_finite(\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input contains NaN."
          ]
        }
      ]
    }
  ]
}